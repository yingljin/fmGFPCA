---
title: "Simulation"
author: "Ying Jin"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 3
    self_contained: false
  pdf_document:
    toc: true
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.kable.NA = '')

set.seed(625)

library(tidyverse)
library(here)
library(kableExtra)
library(ggpubr)
theme_set(theme_minimal())
library(ROCR)

# color
library(RColorBrewer)

load(here("Data/SimOutput/SimOutput_J200.RData"))
load(here("Data/SimOutput/SimOutput_J200_ref.RData"))


# valid_id <- which(pred_time_vec<=10)

```


# Simulation: dynamic prediction

## Simulation set-up

This file documents the simulation scheme of multi-level functional data. 

- Sample size: training = 100, test = 100
- Number of series J = 3
- Number of observations at each vitis K = 200 (when K = 100, numeric issues are likely to happen)
- Make prediction with observations until the middle of series 2 and 3 separately
- 100 simulations



- Binary outcomes: 

$$Y_{ij}(t) \sim Bernoulli(g(\eta_{ij}(t)))$$

$$\eta_{ij}(t)=b_0(t)+\sum_{l=1}^4\xi_{il}\phi_l(t)+\sum_{m=1}^4\zeta_{ijm}\psi_m(t)$$


- Level 1: 

$$\phi_l(t) = \{\sqrt{2}sin(2\pi t), \sqrt2 cos(2\pi t), \sqrt2 sin (4\pi t), \sqrt2 cos(4\pi t)\}$$

$$\xi_{il} \sim N(0, \lambda_l), \hspace{0.5cm} \lambda_l = 0.5^{l-1}, l=1,2, 3, 4$$

## Results

### Figure

```{r color_setting}
cols <- c(brewer.pal(3, "Set2"), "#000000") # define a color palette 
names(cols) <- c("0 full series", "1 full series", "2 full series", "True")
```

```{r pred_sim, fig.height=4, fig.width=12}
rand_id <- sample(101:200, 2)
p1 <- pred_list_allM[[1]] %>%
  filter(id %in% rand_id) %>%
  rename(series = visit) %>% 
  mutate(eta_pred_J1 = ifelse(t<=0.5, NA, eta_pred_J1),
         eta_pred_J2 = ifelse(series==1|(series %in% 2:3 & t<=0.5), NA, eta_pred_J2),
         eta_pred_J3 = ifelse(series %in% 1:2|(series==3&t<=0.5), NA, eta_pred_J3)) %>%
  mutate_at(vars(starts_with("eta_pred")), function(x)(exp(x)/(1+exp(x)))) %>% 
  ggplot()+
  geom_line(aes(x=t, y=probs, col="True"), linewidth=0.5, linetype = "dashed")+
  geom_line(aes(x=t, y=eta_pred_J1, col = "0 full series"), 
            linewidth = 1,
            na.rm = T)+
  geom_line(aes(x=t, y=eta_pred_J2, col = "1 full series"), 
            linewidth = 1,
            na.rm = T)+
  geom_line(aes(x=t, y=eta_pred_J3, col = "2 full series"), 
            linewidth = 1,
            na.rm = T)+
  geom_point(aes(x=t, y=Y,  col="True"), size = 0.2)+
  facet_grid(row = vars(id), col=vars(series))+
  scale_color_manual(values = cols)+
  labs(title = "gmFPCA", color = "", y="", x="t")

p2 <- pred_list_allM_ref[[1]] %>%
  filter(id %in% rand_id) %>%
  rename(series = visit) %>% 
  mutate(eta_pred_J1 = ifelse(t<=0.5, NA, eta_pred_J1),
         eta_pred_J2 = ifelse(series==1|(series %in% 2:3 & t<=0.5), NA, eta_pred_J2),
         eta_pred_J3 = ifelse(series %in% 1:2|(series==3&t<=0.5), NA, eta_pred_J3)) %>%
  mutate_at(vars(starts_with("eta")), function(x)(exp(x)/(1+exp(x)))) %>% 
  ggplot()+
  geom_line(aes(x=t, y=eta, col="True"), linewidth=0.5, linetype = "dashed")+
  geom_line(aes(x=t, y=eta_pred_J1, col = "0 full series"), 
            na.rm = T, alpha = 0.5, linewidth = 1)+
  geom_line(aes(x=t, y=eta_pred_J2, col = "1 full series"), 
            na.rm = T, alpha = 0.5, linewidth = 0.8)+
  geom_line(aes(x=t, y=eta_pred_J3, col = "2 full series"), 
            na.rm = T, alpha = 0.5, linewidth = 0.6)+
  geom_point(aes(x=t, y=Y, col = "True"), size = 0.2)+
  facet_grid(row = vars(id), col=vars(series))+
  scale_color_manual(values=cols)+
  labs(title = "GLMMadaptive", col="", y="", x="t")

ggarrange(p1, p2, nrow=1, common.legend = T, legend = "bottom")
```

### Computation time

```{r}
# print("Computation time:")
data.frame("gmFPCA" = c(mean(fit_time_vec), 
                        mean(pred_time_vec)),
           "GLMMadaptive" = c(mean(fit_time_vec_ref),
                              mean(pred_time_vec_ref))) %>% 
  mutate("Time (mins)" = c("Fit", "Prediction"), .before=1) %>%
  kable(digits = 2) %>% 
  kable_styling(full_width = F)



```


### Integerated squared error



```{r, message=FALSE}
ise_gmfpca <- bind_rows(pred_list_allM, .id = "iter") %>% 
  mutate(window = cut(t, breaks = c(0, 0.5, 1), include.lowest = T)) %>%
  mutate(error_J1 = (eta_pred_J1-eta)^2,
         error_J2 = (eta_pred_J2-eta)^2,
         error_J3 = (eta_pred_J3-eta)^2) %>%
  group_by(iter, visit, window, id) %>%
  summarise_at(vars(starts_with("error_")), sum) %>% 
  group_by(iter, visit, window) %>%
  summarise_at(vars(starts_with("error_")), mean) %>% 
  group_by(visit, window) %>%
  summarise_at(vars(starts_with("error_")), mean)

ise_gmfpca <- ise_gmfpca %>% filter(window == "(0.5,1]")
ise_gmfpca$error_J2[1] <- NA
ise_gmfpca$error_J3[1:2] <- NA
colnames(ise_gmfpca) <- c("visit", "Time",
                          "0 full visit", "1 full visit",
                          "2 full visit")
```


```{r}
ise_glmmad <- bind_rows(pred_list_allM_ref, .id = "iter") %>% 
  mutate(window = cut(t, breaks = c(0, 0.5, 1), include.lowest = T)) %>%
  mutate(error_J1 = (eta_pred_J1-eta)^2,
         error_J2 = (eta_pred_J2-eta)^2,
         error_J3 = (eta_pred_J3-eta)^2) %>%
  group_by(iter, visit, window, id) %>%
  summarise_at(vars(starts_with("error_")), sum) %>% 
  group_by(iter, visit, window) %>%
  summarise_at(vars(starts_with("error_")), mean) %>% 
  group_by(visit, window) %>%
  summarise_at(vars(starts_with("error_")), mean)  

ise_glmmad <- ise_glmmad %>% filter(window == "(0.5,1]")
ise_glmmad$error_J2[1] <- NA
ise_glmmad$error_J3[1:2] <- NA
colnames(ise_glmmad) <- c("visit", "Time",
                          "0 full visit", "1 full visit",
                          "2 full visit")
```

```{r}
# print("Integrated squared error:")
ise_gmfpca %>% 
  add_column(ise_glmmad[,3:5], .name_repair = "minimal") %>%
  kable(digits = 2) %>% 
  kable_styling(full_width = F) %>%
  add_header_above(c(" " = 2, 
                     "gmFPCA" = 3, "GLMMadaptive" = 3)) %>%
  add_header_above(c("Prediction window" = 2,
                         "Observed window" = 6))

```

For series 3, the predictions are identical. This is not a coding error. Because prediction of the three series are made at the same time, and the other series are not identical. 

For GLMM adaptive, it doesn't matter how much data is observed before the prediction window. The prediction stays identical. 


### AUC

```{r, message=FALSE}
auc_gmfpca <- bind_rows(pred_list_allM, .id = "iter") %>% 
  mutate(window = cut(t, breaks = c(0, 0.5, 1), include.lowest = T)) %>%
  group_by(iter, id, visit, window) %>%
  summarize(auc_J1 = performance(prediction(eta_pred_J1, Y),
                               measure = "auc")@y.values[[1]],
            auc_J2 = performance(prediction(eta_pred_J2, Y),
                               measure = "auc")@y.values[[1]],
            auc_J3 = performance(prediction(eta_pred_J3, Y),
                               measure = "auc")@y.values[[1]]) %>% 
  group_by(visit, window) %>%
  summarise_at(vars(starts_with("auc_")), mean)

auc_gmfpca <- auc_gmfpca %>% filter(window == "(0.5,1]")
auc_gmfpca$auc_J2[1] <- NA
auc_gmfpca$auc_J3[1:2] <- NA
colnames(auc_gmfpca) <- c("visit", "Time",
                          "0 full visit", "1 full visit",
                          "2 full visit")

```

```{r, message=FALSE}
auc_glmmad <- bind_rows(pred_list_allM_ref, .id = "iter") %>% 
  mutate(window = cut(t, breaks = c(0, 0.5, 1), include.lowest = T)) %>%
  group_by(iter, id, visit, window) %>%
  summarize(auc_J1 = performance(prediction(eta_pred_J1, Y),
                               measure = "auc")@y.values[[1]],
            auc_J2 = performance(prediction(eta_pred_J2, Y),
                               measure = "auc")@y.values[[1]],
            auc_J3 = performance(prediction(eta_pred_J3, Y),
                               measure = "auc")@y.values[[1]]) %>% 
  group_by(visit, window) %>%
  summarise_at(vars(starts_with("auc_")), mean)


auc_glmmad <- auc_glmmad %>% filter(window == "(0.5,1]")
auc_glmmad$auc_J2[1] <- NA
auc_glmmad$auc_J3[1:2] <- NA
colnames(auc_glmmad) <- c("visit", "Time",
                          "0 full visit", "1 full visit",
                          "2 full visit")


```

```{r}
auc_gmfpca %>% 
  add_column(auc_glmmad[,3:5], .name_repair = "minimal") %>%
  kable(digits = 3) %>% 
  kable_styling(full_width = F) %>%
  add_header_above(c(" " = 2, 
                     "gmFPCA" = 3, "GLMMadaptive" = 3)) %>%
  add_header_above(c("Prediction window" = 2,
                         "Observed window" = 6)) 

```


### Joint table

```{r, message=FALSE}
ise <- ise_gmfpca[,3:5] %>% 
  add_column(ise_glmmad[,3:5], .name_repair = "minimal") %>% 
  as.matrix()

auc <- auc_gmfpca[, 3:5] %>% 
  add_column(auc_glmmad[,3:5], .name_repair = "minimal") %>% 
  as.matrix()

df_perf <- rbind(ise, auc) %>% data.frame() %>%
  mutate(visit = rep(1:3, 2), .before =1)
colnames(df_perf) <- c("visit",
                  rep(c("No full visit", 
                        "1 full visit", 
                        "2 full visit"), 2))

df_perf %>%
  kable(digits = 2) %>%
  kable_styling(full_width = F) %>%
  add_header_above(c(" " = 1, "gmFPCA" = 3, "GLMMadaptive" = 3)) %>%
  add_header_above(c(" " = 1, "Observed data" = 6)) %>%
  group_rows(index = c("ISE" = 3, "AUC" = 3))
  
```


# Simulation: compute missing values

- No need to data splitting. This can be done in all in-sample context.
I can just use the score from mfpca.face model to compute missing value. 
- 100 subjects in total. 10% percent subject, each with 50% missing. 
- For GLMM adaptive, I was able to fit a linear model with id_visit grouping (not nested). The *predict.MixMod* function couldn't make subject-series specific prediction. I had to extract random coefficients and calculate the prediction by hand. 
- Also, GLMM adaptive failed one dataset (43th) due to numeric problem. 

```{r load_mis_output}
load(here("Data/SimOutput/SimOutput_miss.RData"))
load(here("Data/SimOutput/SimOutput_miss_ref.RData"))
```

## Figure

```{r color_setting2}
cols <- c("#66C2A5", "#000000") # define a color palette 
names(cols) <- c("Computed", "Observed/True")
```

```{r miss_sim, fig.width=12, fig.height=4}
rand_id <- sample(unique(comp_list_allM_ref[[1]]$id), 2)

p1 <- comp_list_allM[[1]] %>%
  filter(id %in% rand_id) %>%
  rename(series = visit) %>%
  mutate_at(vars(starts_with("eta")), 
            function(x)(exp(x)/(1+exp(x)))) %>%
  mutate(eta=ifelse(is.na(Yobs), NA, eta),
         eta_comp=ifelse(is.na(Yobs), eta_comp, NA)) %>% 
  ggplot()+
  geom_point(aes(x=t, y=eta, col="Observed/True"), size = 0.1, na.rm = T)+
  geom_point(aes(x=t, y=eta_comp, col="Computed"), size = 0.1, 
             na.rm = T)+
  geom_point(aes(x=t, y=Yobs, col = "Observed/True"), size = 0.1,
             na.rm = T)+
  facet_grid(rows = vars(id), cols = vars(series))+
  scale_color_manual(values = cols)+
  labs(title = "gmFPCA", colour="", y="", x="t")

p2 <- comp_list_allM_ref[[1]] %>%
  filter(id %in% rand_id) %>% 
  rename(series = visit) %>%
  mutate_at(vars(starts_with("eta")), 
            function(x)(exp(x)/(1+exp(x)))) %>%
  mutate(eta=ifelse(is.na(Yobs), NA, eta),
         eta_comp=ifelse(is.na(Yobs), eta_comp, NA)) %>% 
  ggplot()+
  geom_point(aes(x=t, y=eta, col="Observed/True"), size = 0.1, na.rm = T)+
  geom_point(aes(x=t, y=eta_comp, col="Computed"), size = 0.1, 
             na.rm = T)+
  geom_point(aes(x=t, y=Yobs, col="Observed/True"), size = 0.1,
             na.rm = T)+
  facet_grid(rows = vars(id), cols = vars(series))+
  scale_color_manual(values=cols)+
  labs(title = "GLMMadaptive", colour="", y="", x="t")

ggarrange(p1, p2, nrow = 1, common.legend = T, legend = "bottom")
```

## Computation time

```{r}
# print("Computation time:")
data.frame("gmFPCA" = mean(comp_time_vec),
           "GLMMadaptive" = mean(comp_time_vec_ref, na.rm=T)) %>% 
  mutate(" " = "Time (minutes)", .before=1) %>%
  kable(digits = 2) %>% 
  kable_styling(full_width = F)
```


## Integrated squared error

- Average acros all single values

```{r, message=FALSE}
ise_gmfpca2 <- bind_rows(comp_list_allM, .id = "iter") %>% 
  filter(is.na(Yobs)) %>%
  mutate(error = (eta_comp-eta)^2) %>%
  group_by(iter, id) %>% 
  summarize(error = sum(error)) %>%
  ungroup() %>%
  summarise(error = mean(error))

ise_glmmad2 <- bind_rows(comp_list_allM_ref, .id = "iter") %>% 
  filter(is.na(Yobs)) %>%
  mutate(error = (eta_comp-eta)^2) %>%
  group_by(iter, id) %>% 
  summarize(error = sum(error)) %>%
  ungroup() %>%
  summarise(error = mean(error))
```

```{r}
# print("Integrated squared error:")
data.frame("gmFPCA" = ise_gmfpca2[1, 1], 
           "GLMMadaptive"= ise_glmmad2[1, 1]) %>%
  kable(digits = 2) %>% 
  kable_styling(full_width = F)
```

In fact the missing data scenario appears a better illustration. 

## AUC

```{r, message=FALSE}
auc_gmfpca2 <- bind_rows(comp_list_allM, .id = "iter") %>% 
  filter(is.na(Yobs)) %>%
  group_by(iter, id) %>% 
  summarise(auc = performance(prediction(eta_comp, Y),
                              measure = "auc")@y.values[[1]]) %>%
  ungroup() %>%
  summarise(auc = mean(auc))

auc_glmmad2 <- bind_rows(comp_list_allM_ref, .id = "iter") %>% 
  filter(is.na(Yobs)) %>%
  group_by(iter, id) %>% 
  summarise(auc = performance(prediction(eta_comp, Y),
                              measure = "auc")@y.values[[1]]) %>%
  ungroup() %>%
  summarise(auc = mean(auc))
```


```{r}
data.frame("gmFPCA" = auc_gmfpca2[1, 1], 
           "GLMMadaptive"= auc_glmmad2[1, 1]) %>%
  kable(digits = 2) %>% 
  kable_styling(full_width = F)
```